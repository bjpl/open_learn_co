[pytest]
# ═══════════════════════════════════════════════════════════════
# OpenLearn Platform - Root-Level Pytest Configuration
# Test-Driven Development Infrastructure (Week 1 Setup)
# ═══════════════════════════════════════════════════════════════

# Test Discovery Patterns
python_files = test_*.py *_test.py
python_classes = Test*
python_functions = test_*

# Test Paths - Multi-Module Support
testpaths =
    tests
    backend/tests

# Minimum Version Requirements
minversion = 7.0

# Command Line Options (applied automatically)
addopts =
    # Verbosity and Output
    -v
    --strict-markers
    --strict-config
    --tb=short
    --showlocals

    # Coverage Settings (Week 1 Target: 30-40%, Week 3: 70-85%)
    --cov=backend
    --cov=nlp
    --cov=scrapers
    --cov-report=term-missing:skip-covered
    --cov-report=html:htmlcov
    --cov-report=xml:coverage.xml
    --cov-report=json:coverage.json
    --cov-fail-under=30

    # Performance
    --durations=10
    --maxfail=5

    # Warnings
    -W default
    -W ignore::DeprecationWarning

    # Parallel Execution (uncomment when ready)
    # -n auto
    # --dist=loadscope

# Test Markers - Organize and Filter Tests
markers =
    # Test Types
    unit: Unit tests - fast, isolated tests of individual components
    integration: Integration tests - tests of component interactions
    e2e: End-to-end tests - full system workflow tests
    api: API endpoint tests

    # Component-Specific
    scraper: Web scraping tests
    nlp: NLP and text processing tests
    service: Service layer tests
    database: Database interaction tests
    cache: Redis/caching tests

    # Performance & Quality
    slow: Slow-running tests (>1 second)
    fast: Fast tests (<100ms)
    smoke: Smoke tests for basic functionality
    security: Security-focused tests

    # Async Support
    asyncio: Async tests

    # CI/CD
    critical: Critical path tests that must pass
    nightly: Tests run in nightly builds only

    # Feature Flags
    requires_api_key: Tests requiring external API keys
    requires_network: Tests requiring network access

# Async Mode Configuration
asyncio_mode = auto

# Logging Configuration
log_cli = false
log_cli_level = INFO
log_cli_format = %(asctime)s [%(levelname)8s] %(name)s - %(message)s
log_cli_date_format = %Y-%m-%d %H:%M:%S

log_file = tests/test_run.log
log_file_level = DEBUG
log_file_format = %(asctime)s [%(levelname)8s] %(name)s - %(message)s (%(filename)s:%(lineno)d)
log_file_date_format = %Y-%m-%d %H:%M:%S

# Console Output Configuration
console_output_style = progress

# Filter Warnings
filterwarnings =
    error
    ignore::UserWarning
    ignore::DeprecationWarning
    ignore::PendingDeprecationWarning
    ignore::ImportWarning

# ═══════════════════════════════════════════════════════════════
# Coverage Configuration
# ═══════════════════════════════════════════════════════════════

[coverage:run]
source =
    backend
    nlp
    scrapers

omit =
    */tests/*
    */test_*.py
    *_test.py
    */conftest.py
    */__pycache__/*
    */venv/*
    */env/*
    */.venv/*
    */site-packages/*
    */migrations/*
    */node_modules/*
    */__init__.py
    */setup.py

branch = True
parallel = True

[coverage:report]
precision = 2
show_missing = True
skip_covered = False
skip_empty = True
sort = Cover

exclude_lines =
    # Standard exclusions
    pragma: no cover
    def __repr__
    def __str__
    raise AssertionError
    raise NotImplementedError
    if __name__ == .__main__.:
    if TYPE_CHECKING:
    @abstractmethod
    @abc.abstractmethod

    # Debug-only code
    def __init_subclass__
    if self\.debug
    if settings\.DEBUG

    # Protocol/typing
    @overload
    @typing.overload
    Protocol
    @runtime_checkable

[coverage:html]
directory = htmlcov
title = OpenLearn Test Coverage Report

[coverage:xml]
output = coverage.xml

[coverage:json]
output = coverage.json
pretty_print = true

# ═══════════════════════════════════════════════════════════════
# Tool Integration
# ═══════════════════════════════════════════════════════════════

[tool:pytest]
# pytest-xdist settings for parallel execution
addopts =

[tool:pytest-cov]
# Additional pytest-cov settings
show_missing = true

# ═══════════════════════════════════════════════════════════════
# Test Organization Guidelines
# ═══════════════════════════════════════════════════════════════
#
# Directory Structure:
#   tests/
#     ├── unit/           - Fast, isolated component tests
#     ├── integration/    - Component interaction tests
#     ├── e2e/            - Full system workflow tests
#     ├── fixtures/       - Shared test fixtures and factories
#     ├── utils/          - Test utilities and helpers
#     └── conftest.py     - Root-level fixtures
#
# Running Tests:
#   pytest                          # Run all tests
#   pytest -m unit                  # Run only unit tests
#   pytest -m "not slow"            # Skip slow tests
#   pytest --cov                    # Run with coverage
#   pytest -n auto                  # Parallel execution
#   pytest -k "test_api"            # Run tests matching pattern
#
# Coverage Targets:
#   Week 1: 30-40% (Foundation)
#   Week 2: 50-60% (Expansion)
#   Week 3: 70-85% (Comprehensive)
#
# ═══════════════════════════════════════════════════════════════
